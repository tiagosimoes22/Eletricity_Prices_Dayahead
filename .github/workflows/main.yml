name: Web Scraping Diário

on:
  schedule:
    - cron: '0 15 * * *'  
  workflow_dispatch:      # Permite correr manualmente também

jobs:
  run-scraper:
    runs-on: ubuntu-22.04

    steps:
    - name: Clonar repositório
      uses: actions/checkout@v3

    - name: Instalar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Instalar dependências Python
      run: |
        pip install -r requirements.txt

    - name: Instalar Google Chrome e Chromedriver
      run: |
        sudo apt update
        sudo apt install -y wget unzip xvfb libnss3 libxss1 libatk1.0-0 libgtk-3-0 libasound2 fonts-liberation
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt -f install -y
        wget -O chromedriver.zip https://chromedriver.storage.googleapis.com/$(curl -s https://chromedriver.storage.googleapis.com/LATEST_RELEASE)/chromedriver_linux64.zip
        unzip chromedriver.zip
        sudo mv chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver


    - name: Correr script Python com Selenium
      run: |
        export DISPLAY=:99
        Xvfb :99 -screen 0 1920x1080x24 &
        python web_scrap_daily_prices_MNG.py

    - name: Commit e push do Excel gerado
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add output/spot_price_dailyHour_PT.xlsx
        git commit -m "Atualização automática de preços de eletricidade"
        git push
      env:
        GIT_AUTH_TOKEN: ${{ secrets.GH_PAT }}
      continue-on-error: true  # Evita falhar se não houver alterações
